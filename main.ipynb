{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec431c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d3a8aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initializes NLP models and configures the computational device (GPU or CPU).\n",
    "Sets up a spaCy model and two Hugging Face pipelines for classification and\n",
    "sentiment analysis.\n",
    "\"\"\"\n",
    "\n",
    "# Enable tqdm progress bars for pandas operations.\n",
    "tqdm.pandas(desc=\"Processing\")\n",
    "\n",
    "# Load the small English spaCy model for various NLP tasks.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Set device to GPU (0) if available, otherwise set to CPU (-1).\n",
    "if torch.cuda.is_available():\n",
    "    device = 0\n",
    "    print(f\"Using device: GPU\")\n",
    "else:\n",
    "    device = -1\n",
    "    print(f\"Using device: CPU\")\n",
    "\n",
    "# Initialize the zero-shot classification pipeline on the selected device.\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "# Initialize the sentiment analysis pipeline (FinBERT) on the selected device.\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d59fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_to_paragraphs(pdf_path, company_name):\n",
    "    \"\"\"Extracts and cleans text paragraphs from a PDF file.\n",
    "\n",
    "    This function opens a PDF, iterates through each page, and extracts\n",
    "    text blocks. It cleans up the text and filters for blocks longer than\n",
    "    50 characters to identify them as paragraphs.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The full path to the PDF file.\n",
    "        company_name (str): The name of the company associated with the document.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a\n",
    "              parsed paragraph and contains its metadata. Returns an empty\n",
    "              list if the PDF cannot be opened.\n",
    "    \"\"\"\n",
    "    # Attempt to open the PDF file, handling potential errors.\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        # If the file can't be opened, print an error and exit the function.\n",
    "        print(f\"Error opening {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Extract the filename from the full path to use as the document name.\n",
    "    document_name = os.path.basename(pdf_path)\n",
    "    \n",
    "    # Initialize a list to store the results.\n",
    "    parsed_paragraphs = []\n",
    "\n",
    "    # Iterate through each page of the PDF, keeping track of the page number.\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        # Extract all text blocks from the current page.\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        \n",
    "        # Process each individual text block.\n",
    "        for block in blocks:\n",
    "            # The actual text content is at index 4 of the block tuple.\n",
    "            text_segment = block[4]\n",
    "            \n",
    "            # Clean the text by replacing multiple whitespaces with a single space.\n",
    "            clean_text = re.sub(r'\\s+', ' ', text_segment).strip()\n",
    "            \n",
    "            # Filter out short text segments to keep only meaningful paragraphs.\n",
    "            if len(clean_text) > 50:\n",
    "                # Append the paragraph and its metadata as a dictionary to our list.\n",
    "                parsed_paragraphs.append({\n",
    "                    'company': company_name,\n",
    "                    'document_name': document_name,\n",
    "                    'page_number': page_num,\n",
    "                    'paragraph_text': clean_text\n",
    "                })\n",
    "                \n",
    "    # Return the final list of all parsed paragraphs.\n",
    "    return parsed_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dc3af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_VERBS = ['reduce', 'increase', 'achieve', 'commit', 'invest', 'launch', 'develop', 'implement', 'strive', 'aim', 'plan', 'set', 'target']\n",
    "ESG_KEYWORDS = ['emission', 'carbon', 'diversity', 'safety', 'water', 'waste', 'governance', 'ethical', 'supply chain', 'sustainability', 'environmental', 'social', 'inclusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8fb4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_claim(sentence_text):\n",
    "    \"\"\"Determines if a sentence is a potential claim based on a set of rules.\n",
    "\n",
    "    A sentence is considered a claim if it:\n",
    "    1. Is at least 8 words long.\n",
    "    2. Contains a keyword from the global ESG_KEYWORDS list.\n",
    "    3. Contains either an action verb from ACTION_VERBS or a number.\n",
    "\n",
    "    Args:\n",
    "        sentence_text (str): The input sentence to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the sentence meets the claim criteria, otherwise False.\n",
    "    \"\"\"\n",
    "    # Convert the sentence to lowercase for case-insensitive matching.\n",
    "    text = sentence_text.lower()\n",
    "\n",
    "    # Rule 1: A claim must have at least 8 words.\n",
    "    if len(text.split()) < 8:\n",
    "        return False\n",
    "\n",
    "    # Rule 2: A claim must contain at least one ESG-related keyword.\n",
    "    # (Assumes ESG_KEYWORDS is a predefined list of strings).\n",
    "    if not any(keyword in text for keyword in ESG_KEYWORDS):\n",
    "        return False\n",
    "\n",
    "    # Check for the presence of a recognized action verb.\n",
    "    # (Assumes ACTION_VERBS is a predefined list of strings).\n",
    "    has_action = any(verb in text for verb in ACTION_VERBS)\n",
    "\n",
    "    # Check for the presence of any numerical digit.\n",
    "    has_number = any(char.isdigit() for char in text)\n",
    "\n",
    "    # Rule 3: Return True if the sentence has an action verb OR a number.\n",
    "    return has_action or has_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8c63fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_claims_from_paragraphs(paragraph_data):\n",
    "    \"\"\"Processes paragraphs to identify and extract sentences that are claims.\n",
    "\n",
    "    This function iterates through a list of paragraph data, uses a spaCy\n",
    "    model to split each paragraph into sentences, and then evaluates each\n",
    "    sentence using the `is_claim()` helper function.\n",
    "\n",
    "    Args:\n",
    "        paragraph_data (list): A list of dictionaries, where each dictionary\n",
    "                               contains a 'paragraph_text' and its metadata.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list of dictionaries, where each dictionary represents\n",
    "              a single extracted claim and its original metadata.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the results.\n",
    "    extracted_claims = []\n",
    "\n",
    "    # Iterate through each dictionary entry in the input list.\n",
    "    for entry in paragraph_data:\n",
    "        # Process the paragraph text with the pre-loaded spaCy model to parse it.\n",
    "        doc = nlp(entry['paragraph_text'])\n",
    "\n",
    "        # Loop over each sentence segmented by spaCy.\n",
    "        for sent in doc.sents:\n",
    "            # Get the sentence's text and remove leading/trailing whitespace.\n",
    "            sentence_text = sent.text.strip()\n",
    "\n",
    "            # Use the helper function to determine if the sentence is a claim.\n",
    "            if is_claim(sentence_text):\n",
    "                # If it is a claim, append its details to the results list.\n",
    "                extracted_claims.append({\n",
    "                    'company': entry['company'],\n",
    "                    'document_name': entry['document_name'],\n",
    "                    'page_number': entry['page_number'],\n",
    "                    'claim': sentence_text\n",
    "                })\n",
    "\n",
    "    # Return the final list containing all identified claims.\n",
    "    return extracted_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef6e9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_topics = [\"Greenhouse Gas Emissions\", \"Air Quality\", \"Water & Wastewater Management\", \"Energy Management\", \"Waste Management\", \"Ecological Impacts\", \"Employee Health & Safety\", \"Diversity & Inclusion\", \"Labor Practices\", \"Supply Chain Labor Standards\", \"Data Security\", \"Customer Privacy\", \"Product Safety\", \"Business Ethics\", \"Competitive Behavior\", \"Corporate Governance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1bf7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_esg_topic(claim_text, candidate_labels, confidence_threshold=0.7):\n",
    "    \"\"\"Classifies a text into one of several candidate ESG labels.\n",
    "\n",
    "    Uses a pre-initialized zero-shot classification pipeline to categorize the\n",
    "    input text. The classification is only accepted if the model's confidence\n",
    "    score for the top label exceeds the specified threshold.\n",
    "\n",
    "    Args:\n",
    "        claim_text (str): The sentence or claim to be classified.\n",
    "        candidate_labels (list): A list of strings representing the potential\n",
    "                                 ESG topics (e.g., ['Climate', 'Diversity']).\n",
    "        confidence_threshold (float, optional): The minimum confidence score\n",
    "                                                 required to assign a label.\n",
    "                                                 Defaults to 0.7.\n",
    "\n",
    "    Returns:\n",
    "        str: The most likely ESG label if its score is above the threshold,\n",
    "             otherwise returns \"Unclassified\".\n",
    "    \"\"\"\n",
    "    # Handle invalid input: return \"Unclassified\" if the text is not a valid string.\n",
    "    if not isinstance(claim_text, str) or not claim_text:\n",
    "        return \"Unclassified\"\n",
    "\n",
    "    # Run the zero-shot classification model on the input text.\n",
    "    # multi_label=False ensures the scores sum to 1, forcing a single best choice.\n",
    "    result = zero_shot_classifier(claim_text, candidate_labels, multi_label=False)\n",
    "\n",
    "    # Extract the label with the highest probability score.\n",
    "    top_label = result['labels'][0]\n",
    "    # Extract the corresponding highest score.\n",
    "    top_score = result['scores'][0]\n",
    "\n",
    "    # Compare the top score against the confidence threshold.\n",
    "    if top_score > confidence_threshold:\n",
    "        # If the model is confident, return the predicted label.\n",
    "        return top_label\n",
    "    else:\n",
    "        # If the score is too low, the result is considered unclassified.\n",
    "        return \"Unclassified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4d801ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(claim_text):\n",
    "    \"\"\"Analyzes the sentiment of a given text and returns a normalized score.\n",
    "\n",
    "    This function uses a pre-initialized sentiment analysis pipeline to evaluate\n",
    "    a text. It returns a score between -1.0 and 1.0, where positive values\n",
    "    indicate positive sentiment, negative values indicate negative sentiment,\n",
    "    and 0 represents neutral sentiment or invalid input.\n",
    "\n",
    "    Args:\n",
    "        claim_text (str): The text whose sentiment is to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "        float: A sentiment score from -1.0 to 1.0.\n",
    "    \"\"\"\n",
    "    # Return a neutral score for empty or non-string inputs.\n",
    "    if not isinstance(claim_text, str) or not claim_text:\n",
    "        return 0\n",
    "\n",
    "    # Run the pre-loaded sentiment analysis pipeline on the input text.\n",
    "    results = sentiment_analyzer(claim_text)\n",
    "\n",
    "    # Handle cases where the model might not return a result.\n",
    "    if not results:\n",
    "        return 0\n",
    "\n",
    "    # The pipeline returns a list; the main result is the first element.\n",
    "    result = results[0]\n",
    "    \n",
    "    # Extract the confidence score and the sentiment label.\n",
    "    score = result['score']\n",
    "    label = result['label']\n",
    "\n",
    "    # Convert the label and score into a single normalized value.\n",
    "    if label == 'positive':\n",
    "        # Return the score directly for positive sentiment.\n",
    "        return score\n",
    "    elif label == 'negative':\n",
    "        # Invert the score for negative sentiment.\n",
    "        return -score\n",
    "    else:\n",
    "        # Return 0 for neutral sentiment.\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48f6964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_specificity_score(claim_text):\n",
    "    \"\"\"Calculates a normalized specificity score for a given text.\n",
    "\n",
    "    This function scores a claim on a scale of 0.0 to 1.0 based on how\n",
    "    specific it is. Points are awarded for the presence of numbers, future\n",
    "    years, percentages, and specific ESG-related metric keywords.\n",
    "\n",
    "    Args:\n",
    "        claim_text (str): The text to be scored for specificity.\n",
    "\n",
    "    Returns:\n",
    "        float: A normalized score between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "    # Return 0.0 for empty or invalid string input.\n",
    "    if not isinstance(claim_text, str) or not claim_text:\n",
    "        return 0.0\n",
    "\n",
    "    # Initialize score and set the maximum possible score based on 4 rules.\n",
    "    score, max_score = 0, 4.0\n",
    "\n",
    "    # Rule 1: Award a point if the text contains any number.\n",
    "    if re.search(r'\\d', claim_text):\n",
    "        score += 1\n",
    "\n",
    "    # Rule 2: Award a point if a future year (e.g., 2025, 2030) is mentioned.\n",
    "    if re.search(r'\\b(20[2-9][0-9])\\b', claim_text):\n",
    "        score += 1\n",
    "\n",
    "    # Rule 3: Award a point if a percentage is mentioned.\n",
    "    if '%' in claim_text or 'percent' in claim_text.lower():\n",
    "        score += 1\n",
    "\n",
    "    # Rule 4: Award a point for mentioning specific, common ESG metrics.\n",
    "    specific_metrics = ['scope 1', 'scope 2', 'scope 3', 'tco2e', 'kwh', 'mwh', 'baseline']\n",
    "    if any(metric in claim_text.lower() for metric in specific_metrics):\n",
    "        score += 1\n",
    "        \n",
    "    # Normalize the final score to a value between 0.0 and 1.0.\n",
    "    return score / max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e050797",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEDGING_PHRASES = ['aim to', 'strive to', 'plan to', 'work towards', 'hope to', 'could', 'potentially', 'where feasible', 'in the future']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ae2715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hedging_score(claim_text):\n",
    "    \"\"\"Calculates a binary score indicating the presence of hedging language.\n",
    "\n",
    "    This function checks if any predefined hedging phrases (from the global\n",
    "    HEDGING_PHRASES list) are present in the input text. Hedging language\n",
    "    often signals a lack of firm commitment (e.g., \"we aim to\", \"we hope\").\n",
    "\n",
    "    Args:\n",
    "        claim_text (str): The text to be analyzed for hedging.\n",
    "\n",
    "    Returns:\n",
    "        int: Returns 1 if a hedging phrase is found, otherwise returns 0.\n",
    "    \"\"\"\n",
    "    # The `any()` function returns True if a match is found, which is cast to an integer (1).\n",
    "    # If no matches are found, it returns False, which becomes 0.\n",
    "    return int(any(phrase in claim_text.lower() for phrase in HEDGING_PHRASES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bcd6506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_greenwashing_risk(row):\n",
    "    \"\"\"Calculates a greenwashing risk score based on several factors.\n",
    "\n",
    "    This function computes a risk score for a single claim (represented by a row)\n",
    "    by combining its specificity, sentiment, and hedging scores. The formula is\n",
    "    designed so that risk increases with vagueness (low specificity), positive\n",
    "    sentiment, and the presence of hedging language.\n",
    "\n",
    "    Args:\n",
    "        row (pandas.Series): A row from a DataFrame that must contain the keys\n",
    "                             'specificity_score', 'sentiment_score', and\n",
    "                             'hedging_score'.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated greenwashing risk score, rounded to 3 decimal places.\n",
    "    \"\"\"\n",
    "    # Extract the individual scores from the input row for clarity.\n",
    "    specificity_score = row['specificity_score']\n",
    "    sentiment_score = row['sentiment_score']\n",
    "    hedging_score = row['hedging_score']\n",
    "\n",
    "    # Isolate the positive sentiment component, as only positive claims contribute to risk.\n",
    "    positive_sentiment = max(0, sentiment_score)\n",
    "    \n",
    "    # Define the weights for each factor in the risk calculation.\n",
    "    w_spec = 0.5   # Specificity is the most heavily weighted factor.\n",
    "    w_sent = 0.25  # Positive sentiment is a moderate risk factor.\n",
    "    w_hedge = 0.25 # Hedging language is also a moderate risk factor.\n",
    "    \n",
    "    # Invert the specificity score because low specificity (vagueness) increases risk.\n",
    "    inverse_specificity = 1 - specificity_score\n",
    "    \n",
    "    # Calculate the final risk score as a weighted sum of the factors.\n",
    "    risk_score = (w_spec * inverse_specificity) + (w_sent * positive_sentiment) + (w_hedge * hedging_score)\n",
    "          \n",
    "    # Return the final score, rounded for cleaner output.\n",
    "    return round(risk_score, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fc466c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary maps company names to the file paths of their ESG reports.\n",
    "# Each key is a string representing the company, and the corresponding value is the\n",
    "# relative path to its PDF report file.\n",
    "report_files = {\n",
    "    'SekiSui': 'reports/sekisui/ESG_factbook_en.pdf',\n",
    "    'Grasim' : 'reports/Grasim/grasim-industries-esg-data-book-2023-24.pdf',\n",
    "    'Johnosn&Johnson': 'reports/J&J/johnson-johnson-2024-health-for-humanity-report.pdf'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5f5bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Tasks 1: Ingestion and Extraction ---\n",
      "\n",
      "Processing report for: SekiSui...\n",
      "\n",
      "Processing report for: Grasim...\n",
      "\n",
      "Processing report for: Johnosn&Johnson...\n"
     ]
    }
   ],
   "source": [
    "# --- Task 1: Data Ingestion and Claim Extraction ---\n",
    "# This block iterates through the defined report files, parses each PDF,\n",
    "# and extracts sentences that are identified as potential claims.\n",
    "\n",
    "# Log a message to indicate the start of the first major processing stage.\n",
    "print(\"--- Running Tasks 1: Ingestion and Extraction ---\")\n",
    "\n",
    "# Initialize a single list to store all claims extracted from all documents.\n",
    "all_extracted_claims = []\n",
    "\n",
    "# Loop through each company and its corresponding report file path.\n",
    "for company, path in report_files.items():\n",
    "    # Before processing, verify that the PDF file actually exists at the given path.\n",
    "    if not os.path.exists(path):\n",
    "        # If the file is not found, print a warning and skip to the next item in the loop.\n",
    "        print(f\"--- WARNING: File not found for {company} at {path}. Skipping. ---\")\n",
    "        continue\n",
    "\n",
    "    # Announce the start of processing for the current company's report.\n",
    "    print(f\"\\nProcessing report for: {company}...\")\n",
    "\n",
    "    # Step 1.1: Parse the PDF document to extract text into structured paragraphs.\n",
    "    paragraphs = parse_pdf_to_paragraphs(path, company)\n",
    "\n",
    "    # Step 1.2: Sift through the paragraphs to identify and extract claim sentences.\n",
    "    claims = extract_claims_from_paragraphs(paragraphs)\n",
    "\n",
    "    # Add the list of claims from the current document to the master list.\n",
    "    all_extracted_claims.extend(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d851e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Tasks 2: Classification ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 629/629 [07:05<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Task 2: Claim Classification ---\n",
    "# This block converts the extracted claims into a pandas DataFrame and then\n",
    "# classifies each claim into a predefined ESG topic.\n",
    "\n",
    "# Log a message to indicate the start of the classification stage.\n",
    "print(\"--- Running Tasks 2: Classification ---\")\n",
    "\n",
    "# Convert the list of claim dictionaries into a pandas DataFrame for easier analysis.\n",
    "df_claims = pd.DataFrame(all_extracted_claims)\n",
    "\n",
    "# Create a new 'esg_topic' column by classifying each claim's text.\n",
    "# 'progress_apply' is used to show a progress bar during this potentially long-running task.\n",
    "# (Assumes 'esg_topics' is a predefined list of candidate labels).\n",
    "df_claims['esg_topic'] = df_claims['claim'].progress_apply(lambda x: classify_esg_topic(x, esg_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0cbacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Task 3: Sentiment and Specificity Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 629/629 [00:09<00:00, 65.52it/s]\n",
      "Processing: 100%|██████████| 629/629 [00:00<00:00, 78518.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Task 3: Sentiment and Specificity Analysis ---\n",
    "# This block analyzes each claim to determine its sentiment and how\n",
    "# specific its language is, adding the results as new columns to the DataFrame.\n",
    "\n",
    "# Log a message indicating the start of the analysis stage.\n",
    "print(\"\\n--- Running Task 3: Sentiment and Specificity Analysis ---\")\n",
    "\n",
    "# Create a 'sentiment_score' column by applying the sentiment analysis function to each claim.\n",
    "# 'progress_apply' displays a progress bar for this operation.\n",
    "df_claims['sentiment_score'] = df_claims['claim'].progress_apply(analyze_sentiment)\n",
    "\n",
    "# Create a 'specificity_score' column by applying the specificity scoring function to each claim.\n",
    "df_claims['specificity_score'] = df_claims['claim'].progress_apply(calculate_specificity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91e9816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Task 4: Greenwashing Risk Detection ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 629/629 [00:00<00:00, 89778.03it/s]\n",
      "Processing: 100%|██████████| 629/629 [00:00<00:00, 17239.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Task 4: Hedging and Greenwashing Risk Calculation ---\n",
    "# This block identifies hedging language in claims and then calculates a final\n",
    "# greenwashing risk score based on all previously computed metrics.\n",
    "\n",
    "# Log a message to indicate the start of the final analysis stage.\n",
    "print(\"\\n--- Running Task 4: Greenwashing Risk Detection ---\")\n",
    "\n",
    "# Create a 'hedging_score' column by applying the hedging detection function.\n",
    "# This will result in a binary score (1 for hedging, 0 otherwise).\n",
    "df_claims['hedging_score'] = df_claims['claim'].progress_apply(calculate_hedging_score)\n",
    "\n",
    "# Create the final 'greenwashing_risk_score' column by applying the risk calculation.\n",
    "# The function is applied row-wise (axis=1) because it needs access to multiple\n",
    "# columns (specificity, sentiment, hedging) for each claim.\n",
    "df_claims['greenwashing_risk_score'] = df_claims.progress_apply(calculate_greenwashing_risk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4dfc053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All Tasks Complete: Final Summary Table ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>ESG Topic</th>\n",
       "      <th>Extracted Claim</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Specificity Score</th>\n",
       "      <th>Greenwashing Risk Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>This initiative has led several of our units t...</td>\n",
       "      <td>0.947836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>This process leads to significant chemical, wa...</td>\n",
       "      <td>0.858855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Additionally, the company presents Pride Award...</td>\n",
       "      <td>0.837551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>By embedding this price into its operations, U...</td>\n",
       "      <td>0.833619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>The chemical business is one of our most energ...</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Through continuous investments in cutting-edge...</td>\n",
       "      <td>0.777195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>To further our commitment to sustainability, G...</td>\n",
       "      <td>0.742046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>• Developing green belts to restore mined area...</td>\n",
       "      <td>0.676902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Each KPI carries a specific weight and focuses...</td>\n",
       "      <td>0.564947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>He guides the management to ensure Governance,...</td>\n",
       "      <td>0.550691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company     ESG Topic                                    Extracted Claim  \\\n",
       "461  Grasim  Unclassified  This initiative has led several of our units t...   \n",
       "466  Grasim  Unclassified  This process leads to significant chemical, wa...   \n",
       "462  Grasim  Unclassified  Additionally, the company presents Pride Award...   \n",
       "469  Grasim  Unclassified  By embedding this price into its operations, U...   \n",
       "460  Grasim  Unclassified  The chemical business is one of our most energ...   \n",
       "453  Grasim  Unclassified  Through continuous investments in cutting-edge...   \n",
       "475  Grasim  Unclassified  To further our commitment to sustainability, G...   \n",
       "480  Grasim  Unclassified  • Developing green belts to restore mined area...   \n",
       "459  Grasim  Unclassified  Each KPI carries a specific weight and focuses...   \n",
       "438  Grasim  Unclassified  He guides the management to ensure Governance,...   \n",
       "\n",
       "     Sentiment Score  Specificity Score  Greenwashing Risk Score  \n",
       "461         0.947836                0.0                    0.737  \n",
       "466         0.858855                0.0                    0.715  \n",
       "462         0.837551                0.0                    0.709  \n",
       "469         0.833619                0.0                    0.708  \n",
       "460         0.798200                0.0                    0.700  \n",
       "453         0.777195                0.0                    0.694  \n",
       "475         0.742046                0.0                    0.686  \n",
       "480         0.676902                0.0                    0.669  \n",
       "459         0.564947                0.0                    0.641  \n",
       "438         0.550691                0.0                    0.638  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Final Summary ---\n",
    "# This block prepares and displays a clean summary table of the results,\n",
    "# showing the highest-risk claims for each company.\n",
    "\n",
    "# Log a message indicating that all processing is complete.\n",
    "print(\"\\n--- All Tasks Complete: Final Summary Table ---\")\n",
    "\n",
    "# Define the specific columns to be included in the final report.\n",
    "final_columns = [\n",
    "    'company', \n",
    "    'esg_topic', \n",
    "    'claim', \n",
    "    'sentiment_score', \n",
    "    'specificity_score', \n",
    "    'greenwashing_risk_score'\n",
    "]\n",
    "\n",
    "# Create a new, clean DataFrame for the summary.\n",
    "# This involves selecting the desired columns and renaming them for better readability.\n",
    "df_summary = df_claims[final_columns].rename(columns={\n",
    "    'company': 'Company', 'esg_topic': 'ESG Topic', 'claim': 'Extracted Claim', \n",
    "    'sentiment_score': 'Sentiment Score', 'specificity_score': 'Specificity Score', \n",
    "    'greenwashing_risk_score': 'Greenwashing Risk Score'\n",
    "})\n",
    "\n",
    "# Sort the summary table to group by company, and then show the highest risk claims first.\n",
    "# 'inplace=True' modifies the DataFrame directly.\n",
    "df_summary.sort_values(by=['Company', 'Greenwashing Risk Score'], ascending=[True, False], inplace=True)\n",
    "\n",
    "# Display the first 10 rows of the final summary DataFrame.\n",
    "df_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "091594bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>ESG Topic</th>\n",
       "      <th>Extracted Claim</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Specificity Score</th>\n",
       "      <th>Greenwashing Risk Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Diversity &amp; Inclusion</td>\n",
       "      <td>• 8-10 Section Heads / FLOs • Talent pool • Ag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Corporate Governance</td>\n",
       "      <td>As mentioned in the corporate governance secti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Greenhouse Gas Emissions</td>\n",
       "      <td>Parameters Unit FY 2021 FY 2022 FY 2023 FY 202...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Greenhouse Gas Emissions</td>\n",
       "      <td>❖ Indirect Greenhouse Gas Emissions (Scope 2) ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Grasim</td>\n",
       "      <td>Greenhouse Gas Emissions</td>\n",
       "      <td>Parameters Unit FY 2021 FY 2022 FY 2023 FY 202...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company                 ESG Topic  \\\n",
       "484  Grasim     Diversity & Inclusion   \n",
       "435  Grasim      Corporate Governance   \n",
       "439  Grasim  Greenhouse Gas Emissions   \n",
       "440  Grasim  Greenhouse Gas Emissions   \n",
       "441  Grasim  Greenhouse Gas Emissions   \n",
       "\n",
       "                                       Extracted Claim  Sentiment Score  \\\n",
       "484  • 8-10 Section Heads / FLOs • Talent pool • Ag...              0.0   \n",
       "435  As mentioned in the corporate governance secti...              0.0   \n",
       "439  Parameters Unit FY 2021 FY 2022 FY 2023 FY 202...              0.0   \n",
       "440  ❖ Indirect Greenhouse Gas Emissions (Scope 2) ...              0.0   \n",
       "441  Parameters Unit FY 2021 FY 2022 FY 2023 FY 202...              0.0   \n",
       "\n",
       "     Specificity Score  Greenwashing Risk Score  \n",
       "484               0.25                    0.375  \n",
       "435               0.50                    0.250  \n",
       "439               0.50                    0.250  \n",
       "440               0.50                    0.250  \n",
       "441               0.75                    0.125  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary[(df_summary[\"ESG Topic\"] != \"Unclassified\")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19d62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
